{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16654e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\DELL\\\\Downloads\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2ca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert 'Churn' to binary\n",
    "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e744f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Using cached xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f210cbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/e1/4c/4685ccfae9806f561de716e32549190c1f533dde5bcadaf83bdf23972cf0/lightgbm-4.3.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.1)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.3 MB 1.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.3 MB 819.2 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 876.1 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 787.7 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.3 MB 692.4 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.3 MB 655.6 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.3 MB 656.0 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.3 MB 587.7 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.3 MB 587.7 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.3 MB 553.0 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.3 MB 528.4 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.3 MB 507.9 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 488.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.4/1.3 MB 495.2 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.4/1.3 MB 522.0 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.4/1.3 MB 504.4 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 631.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.6/1.3 MB 655.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.6/1.3 MB 655.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.6/1.3 MB 655.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.6/1.3 MB 615.4 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.7/1.3 MB 598.4 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.7/1.3 MB 601.8 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 0.8/1.3 MB 672.9 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 756.6 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.0/1.3 MB 807.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.3 MB 831.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.3 MB 798.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.3 MB 886.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.3 MB 886.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 871.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 858.8 kB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d7eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                        'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3948ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ed1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ccba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_columns = preprocessor.transformers_[0][1]['scaler'].get_feature_names_out(numerical_features)\n",
    "categorical_columns = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=list(numerical_columns) + list(categorical_columns))\n",
    "X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=list(numerical_columns) + list(categorical_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ef6183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "#Q14\n",
    "\n",
    "numerical_columns = preprocessor.transformers_[0][1]['scaler'].get_feature_names_out(numerical_features)\n",
    "categorical_columns = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=list(numerical_columns) + list(categorical_columns))\n",
    "X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=list(numerical_columns) + list(categorical_columns))\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_model.predict(X_test_preprocessed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666ee15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "#Q15\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=1, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "y_pred = xgb_model.predict(X_test_preprocessed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'XGBoost Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a8c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1521, number of negative: 4113\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 46\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.269968 -> initscore=-0.994785\n",
      "[LightGBM] [Info] Start training from score -0.994785\n",
      "LightGBM Accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "#Q16\n",
    "\n",
    "lgbm_model = LGBMClassifier(random_state=1)\n",
    "lgbm_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "y_pred = lgbm_model.predict(X_test_preprocessed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'LightGBM Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f523358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.78949064 0.79020159        nan        nan 0.79162034 0.78771617\n",
      " 0.79002366        nan 0.79250923        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 1000, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt'}\n",
      "Test set accuracy: 0.8041\n"
     ]
    }
   ],
   "source": [
    "#Q17\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'max_features': max_features\n",
    "}\n",
    "\n",
    "# Initializing the Extra Trees Classifier\n",
    "etc = ExtraTreesClassifier(random_state=1)\n",
    "\n",
    "# Initializing RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=etc,\n",
    "                                   param_distributions=hyperparameter_grid,\n",
    "                                   n_iter=10,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1,\n",
    "                                   random_state=1)\n",
    "\n",
    "\n",
    "random_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_preprocessed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e4d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters from RandomizedSearchCV: {'random_state': 1, 'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 30, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Accuracy of the new optimal ExtraTreesClassifier model: 0.8112136266855926\n",
      "Accuracy of the initial ExtraTreesClassifier model: 0.7672107877927609\n"
     ]
    }
   ],
   "source": [
    "#Q18\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': [1]\n",
    "}\n",
    "\n",
    "# Initializing the ExtraTreesClassifier\n",
    "initial_model = ExtraTreesClassifier(random_state=1)\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=initial_model, param_distributions=param_dist, n_iter=50, cv=5, random_state=1, n_jobs=-1)\n",
    "random_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best hyperparameters from RandomizedSearchCV:\", best_params)\n",
    "\n",
    "\n",
    "best_model = ExtraTreesClassifier(**best_params)\n",
    "best_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate accuracy of the new model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Accuracy of the new optimal ExtraTreesClassifier model:\", accuracy_best)\n",
    "\n",
    "# Compare with the initial model (without hyperparameter tuning)\n",
    "initial_model.fit(X_train_preprocessed, y_train)\n",
    "y_pred_initial = initial_model.predict(X_test_preprocessed)\n",
    "accuracy_initial = accuracy_score(y_test, y_pred_initial)\n",
    "print(\"Accuracy of the initial ExtraTreesClassifier model:\", accuracy_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577de9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae1c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d08d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
